{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at dataset\\raw-img. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_dir = \"dataset\"\n",
    "raw_img_dir = os.path.join(dataset_dir, \"raw-img\")\n",
    "\n",
    "if os.path.exists(raw_img_dir) and len(os.listdir(raw_img_dir)) > 0:\n",
    "    print(f\"Dataset already exists at {raw_img_dir}. Skipping download.\")\n",
    "else:\n",
    "    print(\"Dataset not found. Attempting to download...\")\n",
    "    try:\n",
    "        import kagglehub\n",
    "        dataset_path = kagglehub.dataset_download(\"alessiocorrado99/animals10\", path=dataset_dir)\n",
    "        print(f\"Dataset downloaded to: {dataset_path}\")\n",
    "    except ImportError:\n",
    "        print(\"kagglehub not found. Please install it using 'pip install kagglehub'\")\n",
    "        print(\"Attempting manual download...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading dataset: {e}\")\n",
    "        print(f\"Please ensure kagglehub is properly configured and the dataset exists.\")\n",
    "        print(f\"You can also manually download the dataset from Kaggle to {dataset_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for class_name in os.listdir(f\"{dataset_dir}/raw-img\"):\n",
    "    for filename in os.listdir(f\"{dataset_dir}/raw-img/{class_name}\"):\n",
    "        data.append({\"filename\": f\"{dataset_dir}/raw-img/{class_name}/{filename}\", \"class\": class_name})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(f\"{dataset_dir}/_annotations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split and reorganized into train, test, and valid directories.\n"
     ]
    }
   ],
   "source": [
    "# Read the annotations file\n",
    "df = pd.read_csv(f\"{dataset_dir}/_annotations.csv\")\n",
    "\n",
    "# Create train, test, valid directories\n",
    "for split in ['train', 'test', 'valid']:\n",
    "    os.makedirs(os.path.join(dataset_dir, split), exist_ok=True)\n",
    "\n",
    "# Split the data\n",
    "train_df, test_valid_df = train_test_split(df, test_size=0.3, stratify=df['class'], random_state=42)\n",
    "valid_df, test_df = train_test_split(test_valid_df, test_size=0.5, stratify=test_valid_df['class'], random_state=42)\n",
    "\n",
    "# Function to copy files and create new annotations\n",
    "def process_split(split_df, split_name):\n",
    "    new_annotations = []\n",
    "    for _, row in split_df.iterrows():\n",
    "        src = row['filename']\n",
    "        dst = os.path.join(dataset_dir, split_name, os.path.basename(src))\n",
    "        shutil.copy(src, dst)\n",
    "        new_annotations.append({'filename': os.path.basename(src), 'class': row['class']})\n",
    "    \n",
    "    new_df = pd.DataFrame(new_annotations)\n",
    "    new_df.to_csv(os.path.join(dataset_dir, f'{split_name}_annotations.csv'), index=False)\n",
    "\n",
    "# Process each split\n",
    "process_split(train_df, 'train')\n",
    "process_split(valid_df, 'valid')\n",
    "process_split(test_df, 'test')\n",
    "\n",
    "print(\"Data split and reorganized into train, test, and valid directories.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18325 validated image filenames belonging to 10 classes.\n",
      "Found 3927 validated image filenames belonging to 10 classes.\n",
      "Found 18325 images belonging to 10 classes in the training set.\n",
      "Found 3927 images belonging to 10 classes in the validation set.\n"
     ]
    }
   ],
   "source": [
    "# Set up paths\n",
    "dataset_dir = \"dataset\"\n",
    "raw_img_dir = os.path.join(dataset_dir, \"raw-img\")\n",
    "annotations_file = os.path.join(dataset_dir, \"_annotations.csv\")\n",
    "\n",
    "# Create annotations file if it doesn't exist\n",
    "if not os.path.exists(annotations_file):\n",
    "    data = []\n",
    "    for class_name in os.listdir(raw_img_dir):\n",
    "        class_dir = os.path.join(raw_img_dir, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            data.append({\"filename\": os.path.join(class_dir, filename), \"class\": class_name})\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(annotations_file, index=False)\n",
    "\n",
    "# Read the annotations file\n",
    "df = pd.read_csv(annotations_file)\n",
    "\n",
    "# Create train, test, valid directories\n",
    "for split in ['train', 'test', 'valid']:\n",
    "    os.makedirs(os.path.join(dataset_dir, split), exist_ok=True)\n",
    "\n",
    "# Split the data\n",
    "train_df, test_valid_df = train_test_split(df, test_size=0.3, stratify=df['class'], random_state=42)\n",
    "valid_df, test_df = train_test_split(test_valid_df, test_size=0.5, stratify=test_valid_df['class'], random_state=42)\n",
    "\n",
    "# Function to create new annotations\n",
    "def create_split_annotations(split_df, split_name):\n",
    "    split_dir = os.path.join(dataset_dir, split_name)\n",
    "    split_df['filename'] = split_df['filename'].apply(lambda x: os.path.join(split_dir, os.path.basename(x)))\n",
    "    split_df.to_csv(os.path.join(dataset_dir, f'{split_name}_annotations.csv'), index=False)\n",
    "\n",
    "# Create split annotations\n",
    "create_split_annotations(train_df, 'train')\n",
    "create_split_annotations(valid_df, 'valid')\n",
    "create_split_annotations(test_df, 'test')\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Set up data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Load and preprocess the data\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=pd.read_csv(os.path.join(dataset_dir, 'train_annotations.csv')),\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=pd.read_csv(os.path.join(dataset_dir, 'valid_annotations.csv')),\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "print(f\"Found {len(train_generator.filenames)} images belonging to {len(train_generator.class_indices)} classes in the training set.\")\n",
    "print(f\"Found {len(validation_generator.filenames)} images belonging to {len(validation_generator.class_indices)} classes in the validation set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94668760/94668760 [==============================] - 6s 0us/step\n",
      "Phase 1: Training top layers...\n",
      "Epoch 1/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.9326 - accuracy: 0.7121\n",
      "Epoch 1: val_accuracy improved from -inf to 0.91547, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 336s 1s/step - loss: 0.9326 - accuracy: 0.7121 - val_loss: 0.2960 - val_accuracy: 0.9155 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.4437 - accuracy: 0.8653\n",
      "Epoch 2: val_accuracy improved from 0.91547 to 0.92572, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 297s 1s/step - loss: 0.4437 - accuracy: 0.8653 - val_loss: 0.2472 - val_accuracy: 0.9257 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.3781 - accuracy: 0.8842\n",
      "Epoch 3: val_accuracy did not improve from 0.92572\n",
      "286/286 [==============================] - 297s 1s/step - loss: 0.3781 - accuracy: 0.8842 - val_loss: 0.2316 - val_accuracy: 0.9249 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.3381 - accuracy: 0.8964\n",
      "Epoch 4: val_accuracy improved from 0.92572 to 0.92802, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 301s 1s/step - loss: 0.3381 - accuracy: 0.8964 - val_loss: 0.2366 - val_accuracy: 0.9280 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.3022 - accuracy: 0.9046\n",
      "Epoch 5: val_accuracy improved from 0.92802 to 0.93519, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 302s 1s/step - loss: 0.3022 - accuracy: 0.9046 - val_loss: 0.2151 - val_accuracy: 0.9352 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2829 - accuracy: 0.9096\n",
      "Epoch 6: val_accuracy improved from 0.93519 to 0.93648, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 290s 1s/step - loss: 0.2829 - accuracy: 0.9096 - val_loss: 0.2091 - val_accuracy: 0.9365 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.9147\n",
      "Epoch 7: val_accuracy did not improve from 0.93648\n",
      "286/286 [==============================] - 294s 1s/step - loss: 0.2763 - accuracy: 0.9147 - val_loss: 0.2126 - val_accuracy: 0.9360 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2581 - accuracy: 0.9174\n",
      "Epoch 8: val_accuracy did not improve from 0.93648\n",
      "286/286 [==============================] - 296s 1s/step - loss: 0.2581 - accuracy: 0.9174 - val_loss: 0.2092 - val_accuracy: 0.9344 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2457 - accuracy: 0.9230\n",
      "Epoch 9: val_accuracy improved from 0.93648 to 0.94083, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 296s 1s/step - loss: 0.2457 - accuracy: 0.9230 - val_loss: 0.2013 - val_accuracy: 0.9408 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2356 - accuracy: 0.9254\n",
      "Epoch 10: val_accuracy improved from 0.94083 to 0.94185, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 295s 1s/step - loss: 0.2356 - accuracy: 0.9254 - val_loss: 0.2118 - val_accuracy: 0.9419 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.9279\n",
      "Epoch 11: val_accuracy improved from 0.94185 to 0.94493, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 299s 1s/step - loss: 0.2295 - accuracy: 0.9279 - val_loss: 0.1886 - val_accuracy: 0.9449 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2266 - accuracy: 0.9289\n",
      "Epoch 12: val_accuracy improved from 0.94493 to 0.94621, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 302s 1s/step - loss: 0.2266 - accuracy: 0.9289 - val_loss: 0.1854 - val_accuracy: 0.9462 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2211 - accuracy: 0.9289\n",
      "Epoch 13: val_accuracy did not improve from 0.94621\n",
      "286/286 [==============================] - 291s 1s/step - loss: 0.2211 - accuracy: 0.9289 - val_loss: 0.1963 - val_accuracy: 0.9447 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2160 - accuracy: 0.9321\n",
      "Epoch 14: val_accuracy did not improve from 0.94621\n",
      "286/286 [==============================] - 293s 1s/step - loss: 0.2160 - accuracy: 0.9321 - val_loss: 0.2002 - val_accuracy: 0.9413 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2098 - accuracy: 0.9340\n",
      "Epoch 15: val_accuracy did not improve from 0.94621\n",
      "286/286 [==============================] - 291s 1s/step - loss: 0.2098 - accuracy: 0.9340 - val_loss: 0.1986 - val_accuracy: 0.9408 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2055 - accuracy: 0.9360\n",
      "Epoch 16: val_accuracy did not improve from 0.94621\n",
      "286/286 [==============================] - 293s 1s/step - loss: 0.2055 - accuracy: 0.9360 - val_loss: 0.1825 - val_accuracy: 0.9462 - lr: 2.0000e-05\n",
      "Epoch 17/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.9369\n",
      "Epoch 17: val_accuracy did not improve from 0.94621\n",
      "286/286 [==============================] - 295s 1s/step - loss: 0.1990 - accuracy: 0.9369 - val_loss: 0.1906 - val_accuracy: 0.9452 - lr: 2.0000e-05\n",
      "Epoch 18/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1950 - accuracy: 0.9371\n",
      "Epoch 18: val_accuracy improved from 0.94621 to 0.94672, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 296s 1s/step - loss: 0.1950 - accuracy: 0.9371 - val_loss: 0.1918 - val_accuracy: 0.9467 - lr: 2.0000e-05\n",
      "Epoch 19/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1945 - accuracy: 0.9379\n",
      "Epoch 19: val_accuracy did not improve from 0.94672\n",
      "286/286 [==============================] - 296s 1s/step - loss: 0.1945 - accuracy: 0.9379 - val_loss: 0.1916 - val_accuracy: 0.9424 - lr: 2.0000e-05\n",
      "Epoch 20/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 0.9405\n",
      "Epoch 20: val_accuracy did not improve from 0.94672\n",
      "286/286 [==============================] - 295s 1s/step - loss: 0.1875 - accuracy: 0.9405 - val_loss: 0.2028 - val_accuracy: 0.9390 - lr: 4.0000e-06\n",
      "\n",
      "Phase 2: Fine-tuning ResNet layers...\n",
      "Epoch 1/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2598 - accuracy: 0.9156\n",
      "Epoch 1: val_accuracy did not improve from 0.94672\n",
      "286/286 [==============================] - 449s 2s/step - loss: 0.2598 - accuracy: 0.9156 - val_loss: 0.2056 - val_accuracy: 0.9337 - lr: 1.0000e-05\n",
      "Epoch 2/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2084 - accuracy: 0.9335\n",
      "Epoch 2: val_accuracy did not improve from 0.94672\n",
      "286/286 [==============================] - 452s 2s/step - loss: 0.2084 - accuracy: 0.9335 - val_loss: 0.2082 - val_accuracy: 0.9413 - lr: 1.0000e-05\n",
      "Epoch 3/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 0.9408\n",
      "Epoch 3: val_accuracy did not improve from 0.94672\n",
      "286/286 [==============================] - 455s 2s/step - loss: 0.1875 - accuracy: 0.9408 - val_loss: 0.1957 - val_accuracy: 0.9465 - lr: 1.0000e-05\n",
      "Epoch 4/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1826 - accuracy: 0.9426\n",
      "Epoch 4: val_accuracy did not improve from 0.94672\n",
      "286/286 [==============================] - 455s 2s/step - loss: 0.1826 - accuracy: 0.9426 - val_loss: 0.1884 - val_accuracy: 0.9467 - lr: 1.0000e-05\n",
      "Epoch 5/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.9480\n",
      "Epoch 5: val_accuracy did not improve from 0.94672\n",
      "286/286 [==============================] - 446s 2s/step - loss: 0.1656 - accuracy: 0.9480 - val_loss: 0.1919 - val_accuracy: 0.9465 - lr: 1.0000e-05\n",
      "Epoch 6/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1512 - accuracy: 0.9524\n",
      "Epoch 6: val_accuracy improved from 0.94672 to 0.94903, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 445s 2s/step - loss: 0.1512 - accuracy: 0.9524 - val_loss: 0.1769 - val_accuracy: 0.9490 - lr: 1.0000e-05\n",
      "Epoch 7/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1513 - accuracy: 0.9504\n",
      "Epoch 7: val_accuracy improved from 0.94903 to 0.95338, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 442s 2s/step - loss: 0.1513 - accuracy: 0.9504 - val_loss: 0.1785 - val_accuracy: 0.9534 - lr: 1.0000e-05\n",
      "Epoch 8/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1349 - accuracy: 0.9568\n",
      "Epoch 8: val_accuracy did not improve from 0.95338\n",
      "286/286 [==============================] - 441s 2s/step - loss: 0.1349 - accuracy: 0.9568 - val_loss: 0.1899 - val_accuracy: 0.9477 - lr: 1.0000e-05\n",
      "Epoch 9/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1271 - accuracy: 0.9593\n",
      "Epoch 9: val_accuracy did not improve from 0.95338\n",
      "286/286 [==============================] - 447s 2s/step - loss: 0.1271 - accuracy: 0.9593 - val_loss: 0.1772 - val_accuracy: 0.9531 - lr: 1.0000e-05\n",
      "Epoch 10/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.9604\n",
      "Epoch 10: val_accuracy improved from 0.95338 to 0.95645, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 446s 2s/step - loss: 0.1226 - accuracy: 0.9604 - val_loss: 0.1715 - val_accuracy: 0.9565 - lr: 2.0000e-06\n",
      "Epoch 11/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.9619\n",
      "Epoch 11: val_accuracy did not improve from 0.95645\n",
      "286/286 [==============================] - 443s 2s/step - loss: 0.1184 - accuracy: 0.9619 - val_loss: 0.1797 - val_accuracy: 0.9498 - lr: 2.0000e-06\n",
      "Epoch 12/30\n",
      "256/286 [=========================>....] - ETA: 43s - loss: 0.1211 - accuracy: 0.9624"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 107\u001b[0m\n\u001b[0;32m    100\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m    101\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m),\n\u001b[0;32m    102\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    103\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    104\u001b[0m )\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Continue training\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m history2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_improved_model(input_shape, num_classes):\n",
    "    # Create base model with pre-trained ResNet50V2\n",
    "    base_model = applications.ResNet50V2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    # Freeze the base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Create the model\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# Create and compile the model\n",
    "model = create_improved_model(input_shape, num_classes)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Create callbacks\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Create checkpoint callback\n",
    "checkpoint_dir = 'checkpoints'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'model_checkpoint.h5')\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Function to load the latest checkpoint\n",
    "def load_latest_checkpoint(model, checkpoint_path):\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Loading weights from checkpoint: {checkpoint_path}\")\n",
    "        model.load_weights(checkpoint_path)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Load checkpoint if it exists\n",
    "load_latest_checkpoint(model, checkpoint_path)\n",
    "\n",
    "# Phase 1: Train only the top layers\n",
    "print(\"Phase 1: Training top layers...\")\n",
    "history1 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Phase 2: Fine-tune the last few layers of ResNet\n",
    "print(\"\\nPhase 2: Fine-tuning ResNet layers...\")\n",
    "base_model = model.layers[0]\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-30]:  # Freeze all but the last 30 layers\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with a lower learning rate\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Continue training\n",
    "history2 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=30,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(f'Test accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Save the model\n",
    "model.save('animal_classification_model.tf')\n",
    "print(\"Model saved as animal_classification_model.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight file structure:\n",
      "batch_normalization/batch_normalization/beta:0: (2048,)\n",
      "batch_normalization/batch_normalization/gamma:0: (2048,)\n",
      "batch_normalization/batch_normalization/moving_mean:0: (2048,)\n",
      "batch_normalization/batch_normalization/moving_variance:0: (2048,)\n",
      "dense_4/dense_4/bias:0: (512,)\n",
      "dense_4/dense_4/kernel:0: (2048, 512)\n",
      "dense_5/dense_5/bias:0: (256,)\n",
      "dense_5/dense_5/kernel:0: (512, 256)\n",
      "dense_6/dense_6/bias:0: (10,)\n",
      "dense_6/dense_6/kernel:0: (256, 10)\n",
      "resnet50v2/conv1_conv/bias:0: (64,)\n",
      "resnet50v2/conv1_conv/kernel:0: (7, 7, 3, 64)\n",
      "resnet50v2/conv2_block1_0_conv/bias:0: (256,)\n",
      "resnet50v2/conv2_block1_0_conv/kernel:0: (1, 1, 64, 256)\n",
      "resnet50v2/conv2_block1_1_bn/beta:0: (64,)\n",
      "resnet50v2/conv2_block1_1_bn/gamma:0: (64,)\n",
      "resnet50v2/conv2_block1_1_bn/moving_mean:0: (64,)\n",
      "resnet50v2/conv2_block1_1_bn/moving_variance:0: (64,)\n",
      "resnet50v2/conv2_block1_1_conv/kernel:0: (1, 1, 64, 64)\n",
      "resnet50v2/conv2_block1_2_bn/beta:0: (64,)\n",
      "resnet50v2/conv2_block1_2_bn/gamma:0: (64,)\n",
      "resnet50v2/conv2_block1_2_bn/moving_mean:0: (64,)\n",
      "resnet50v2/conv2_block1_2_bn/moving_variance:0: (64,)\n",
      "resnet50v2/conv2_block1_2_conv/kernel:0: (3, 3, 64, 64)\n",
      "resnet50v2/conv2_block1_3_conv/bias:0: (256,)\n",
      "resnet50v2/conv2_block1_3_conv/kernel:0: (1, 1, 64, 256)\n",
      "resnet50v2/conv2_block1_preact_bn/beta:0: (64,)\n",
      "resnet50v2/conv2_block1_preact_bn/gamma:0: (64,)\n",
      "resnet50v2/conv2_block1_preact_bn/moving_mean:0: (64,)\n",
      "resnet50v2/conv2_block1_preact_bn/moving_variance:0: (64,)\n",
      "resnet50v2/conv2_block2_1_bn/beta:0: (64,)\n",
      "resnet50v2/conv2_block2_1_bn/gamma:0: (64,)\n",
      "resnet50v2/conv2_block2_1_bn/moving_mean:0: (64,)\n",
      "resnet50v2/conv2_block2_1_bn/moving_variance:0: (64,)\n",
      "resnet50v2/conv2_block2_1_conv/kernel:0: (1, 1, 256, 64)\n",
      "resnet50v2/conv2_block2_2_bn/beta:0: (64,)\n",
      "resnet50v2/conv2_block2_2_bn/gamma:0: (64,)\n",
      "resnet50v2/conv2_block2_2_bn/moving_mean:0: (64,)\n",
      "resnet50v2/conv2_block2_2_bn/moving_variance:0: (64,)\n",
      "resnet50v2/conv2_block2_2_conv/kernel:0: (3, 3, 64, 64)\n",
      "resnet50v2/conv2_block2_3_conv/bias:0: (256,)\n",
      "resnet50v2/conv2_block2_3_conv/kernel:0: (1, 1, 64, 256)\n",
      "resnet50v2/conv2_block2_preact_bn/beta:0: (256,)\n",
      "resnet50v2/conv2_block2_preact_bn/gamma:0: (256,)\n",
      "resnet50v2/conv2_block2_preact_bn/moving_mean:0: (256,)\n",
      "resnet50v2/conv2_block2_preact_bn/moving_variance:0: (256,)\n",
      "resnet50v2/conv2_block3_1_bn/beta:0: (64,)\n",
      "resnet50v2/conv2_block3_1_bn/gamma:0: (64,)\n",
      "resnet50v2/conv2_block3_1_bn/moving_mean:0: (64,)\n",
      "resnet50v2/conv2_block3_1_bn/moving_variance:0: (64,)\n",
      "resnet50v2/conv2_block3_1_conv/kernel:0: (1, 1, 256, 64)\n",
      "resnet50v2/conv2_block3_2_bn/beta:0: (64,)\n",
      "resnet50v2/conv2_block3_2_bn/gamma:0: (64,)\n",
      "resnet50v2/conv2_block3_2_bn/moving_mean:0: (64,)\n",
      "resnet50v2/conv2_block3_2_bn/moving_variance:0: (64,)\n",
      "resnet50v2/conv2_block3_2_conv/kernel:0: (3, 3, 64, 64)\n",
      "resnet50v2/conv2_block3_3_conv/bias:0: (256,)\n",
      "resnet50v2/conv2_block3_3_conv/kernel:0: (1, 1, 64, 256)\n",
      "resnet50v2/conv2_block3_preact_bn/beta:0: (256,)\n",
      "resnet50v2/conv2_block3_preact_bn/gamma:0: (256,)\n",
      "resnet50v2/conv2_block3_preact_bn/moving_mean:0: (256,)\n",
      "resnet50v2/conv2_block3_preact_bn/moving_variance:0: (256,)\n",
      "resnet50v2/conv3_block1_0_conv/bias:0: (512,)\n",
      "resnet50v2/conv3_block1_0_conv/kernel:0: (1, 1, 256, 512)\n",
      "resnet50v2/conv3_block1_1_bn/beta:0: (128,)\n",
      "resnet50v2/conv3_block1_1_bn/gamma:0: (128,)\n",
      "resnet50v2/conv3_block1_1_bn/moving_mean:0: (128,)\n",
      "resnet50v2/conv3_block1_1_bn/moving_variance:0: (128,)\n",
      "resnet50v2/conv3_block1_1_conv/kernel:0: (1, 1, 256, 128)\n",
      "resnet50v2/conv3_block1_2_bn/beta:0: (128,)\n",
      "resnet50v2/conv3_block1_2_bn/gamma:0: (128,)\n",
      "resnet50v2/conv3_block1_2_bn/moving_mean:0: (128,)\n",
      "resnet50v2/conv3_block1_2_bn/moving_variance:0: (128,)\n",
      "resnet50v2/conv3_block1_2_conv/kernel:0: (3, 3, 128, 128)\n",
      "resnet50v2/conv3_block1_3_conv/bias:0: (512,)\n",
      "resnet50v2/conv3_block1_3_conv/kernel:0: (1, 1, 128, 512)\n",
      "resnet50v2/conv3_block1_preact_bn/beta:0: (256,)\n",
      "resnet50v2/conv3_block1_preact_bn/gamma:0: (256,)\n",
      "resnet50v2/conv3_block1_preact_bn/moving_mean:0: (256,)\n",
      "resnet50v2/conv3_block1_preact_bn/moving_variance:0: (256,)\n",
      "resnet50v2/conv3_block2_1_bn/beta:0: (128,)\n",
      "resnet50v2/conv3_block2_1_bn/gamma:0: (128,)\n",
      "resnet50v2/conv3_block2_1_bn/moving_mean:0: (128,)\n",
      "resnet50v2/conv3_block2_1_bn/moving_variance:0: (128,)\n",
      "resnet50v2/conv3_block2_1_conv/kernel:0: (1, 1, 512, 128)\n",
      "resnet50v2/conv3_block2_2_bn/beta:0: (128,)\n",
      "resnet50v2/conv3_block2_2_bn/gamma:0: (128,)\n",
      "resnet50v2/conv3_block2_2_bn/moving_mean:0: (128,)\n",
      "resnet50v2/conv3_block2_2_bn/moving_variance:0: (128,)\n",
      "resnet50v2/conv3_block2_2_conv/kernel:0: (3, 3, 128, 128)\n",
      "resnet50v2/conv3_block2_3_conv/bias:0: (512,)\n",
      "resnet50v2/conv3_block2_3_conv/kernel:0: (1, 1, 128, 512)\n",
      "resnet50v2/conv3_block2_preact_bn/beta:0: (512,)\n",
      "resnet50v2/conv3_block2_preact_bn/gamma:0: (512,)\n",
      "resnet50v2/conv3_block2_preact_bn/moving_mean:0: (512,)\n",
      "resnet50v2/conv3_block2_preact_bn/moving_variance:0: (512,)\n",
      "resnet50v2/conv3_block3_1_bn/beta:0: (128,)\n",
      "resnet50v2/conv3_block3_1_bn/gamma:0: (128,)\n",
      "resnet50v2/conv3_block3_1_bn/moving_mean:0: (128,)\n",
      "resnet50v2/conv3_block3_1_bn/moving_variance:0: (128,)\n",
      "resnet50v2/conv3_block3_1_conv/kernel:0: (1, 1, 512, 128)\n",
      "resnet50v2/conv3_block3_2_bn/beta:0: (128,)\n",
      "resnet50v2/conv3_block3_2_bn/gamma:0: (128,)\n",
      "resnet50v2/conv3_block3_2_bn/moving_mean:0: (128,)\n",
      "resnet50v2/conv3_block3_2_bn/moving_variance:0: (128,)\n",
      "resnet50v2/conv3_block3_2_conv/kernel:0: (3, 3, 128, 128)\n",
      "resnet50v2/conv3_block3_3_conv/bias:0: (512,)\n",
      "resnet50v2/conv3_block3_3_conv/kernel:0: (1, 1, 128, 512)\n",
      "resnet50v2/conv3_block3_preact_bn/beta:0: (512,)\n",
      "resnet50v2/conv3_block3_preact_bn/gamma:0: (512,)\n",
      "resnet50v2/conv3_block3_preact_bn/moving_mean:0: (512,)\n",
      "resnet50v2/conv3_block3_preact_bn/moving_variance:0: (512,)\n",
      "resnet50v2/conv3_block4_1_bn/beta:0: (128,)\n",
      "resnet50v2/conv3_block4_1_bn/gamma:0: (128,)\n",
      "resnet50v2/conv3_block4_1_bn/moving_mean:0: (128,)\n",
      "resnet50v2/conv3_block4_1_bn/moving_variance:0: (128,)\n",
      "resnet50v2/conv3_block4_1_conv/kernel:0: (1, 1, 512, 128)\n",
      "resnet50v2/conv3_block4_2_bn/beta:0: (128,)\n",
      "resnet50v2/conv3_block4_2_bn/gamma:0: (128,)\n",
      "resnet50v2/conv3_block4_2_bn/moving_mean:0: (128,)\n",
      "resnet50v2/conv3_block4_2_bn/moving_variance:0: (128,)\n",
      "resnet50v2/conv3_block4_2_conv/kernel:0: (3, 3, 128, 128)\n",
      "resnet50v2/conv3_block4_3_conv/bias:0: (512,)\n",
      "resnet50v2/conv3_block4_3_conv/kernel:0: (1, 1, 128, 512)\n",
      "resnet50v2/conv3_block4_preact_bn/beta:0: (512,)\n",
      "resnet50v2/conv3_block4_preact_bn/gamma:0: (512,)\n",
      "resnet50v2/conv3_block4_preact_bn/moving_mean:0: (512,)\n",
      "resnet50v2/conv3_block4_preact_bn/moving_variance:0: (512,)\n",
      "resnet50v2/conv4_block1_0_conv/bias:0: (1024,)\n",
      "resnet50v2/conv4_block1_0_conv/kernel:0: (1, 1, 512, 1024)\n",
      "resnet50v2/conv4_block1_1_bn/beta:0: (256,)\n",
      "resnet50v2/conv4_block1_1_bn/gamma:0: (256,)\n",
      "resnet50v2/conv4_block1_1_bn/moving_mean:0: (256,)\n",
      "resnet50v2/conv4_block1_1_bn/moving_variance:0: (256,)\n",
      "resnet50v2/conv4_block1_1_conv/kernel:0: (1, 1, 512, 256)\n",
      "resnet50v2/conv4_block1_2_bn/beta:0: (256,)\n",
      "resnet50v2/conv4_block1_2_bn/gamma:0: (256,)\n",
      "resnet50v2/conv4_block1_2_bn/moving_mean:0: (256,)\n",
      "resnet50v2/conv4_block1_2_bn/moving_variance:0: (256,)\n",
      "resnet50v2/conv4_block1_2_conv/kernel:0: (3, 3, 256, 256)\n",
      "resnet50v2/conv4_block1_3_conv/bias:0: (1024,)\n",
      "resnet50v2/conv4_block1_3_conv/kernel:0: (1, 1, 256, 1024)\n",
      "resnet50v2/conv4_block1_preact_bn/beta:0: (512,)\n",
      "resnet50v2/conv4_block1_preact_bn/gamma:0: (512,)\n",
      "resnet50v2/conv4_block1_preact_bn/moving_mean:0: (512,)\n",
      "resnet50v2/conv4_block1_preact_bn/moving_variance:0: (512,)\n",
      "resnet50v2/conv4_block2_1_bn/beta:0: (256,)\n",
      "resnet50v2/conv4_block2_1_bn/gamma:0: (256,)\n",
      "resnet50v2/conv4_block2_1_bn/moving_mean:0: (256,)\n",
      "resnet50v2/conv4_block2_1_bn/moving_variance:0: (256,)\n",
      "resnet50v2/conv4_block2_1_conv/kernel:0: (1, 1, 1024, 256)\n",
      "resnet50v2/conv4_block2_2_bn/beta:0: (256,)\n",
      "resnet50v2/conv4_block2_2_bn/gamma:0: (256,)\n",
      "resnet50v2/conv4_block2_2_bn/moving_mean:0: (256,)\n",
      "resnet50v2/conv4_block2_2_bn/moving_variance:0: (256,)\n",
      "resnet50v2/conv4_block2_2_conv/kernel:0: (3, 3, 256, 256)\n",
      "resnet50v2/conv4_block2_3_conv/bias:0: (1024,)\n",
      "resnet50v2/conv4_block2_3_conv/kernel:0: (1, 1, 256, 1024)\n",
      "resnet50v2/conv4_block2_preact_bn/beta:0: (1024,)\n",
      "resnet50v2/conv4_block2_preact_bn/gamma:0: (1024,)\n",
      "resnet50v2/conv4_block2_preact_bn/moving_mean:0: (1024,)\n",
      "resnet50v2/conv4_block2_preact_bn/moving_variance:0: (1024,)\n",
      "resnet50v2/conv4_block3_1_bn/beta:0: (256,)\n",
      "resnet50v2/conv4_block3_1_bn/gamma:0: (256,)\n",
      "resnet50v2/conv4_block3_1_bn/moving_mean:0: (256,)\n",
      "resnet50v2/conv4_block3_1_bn/moving_variance:0: (256,)\n",
      "resnet50v2/conv4_block3_1_conv/kernel:0: (1, 1, 1024, 256)\n",
      "resnet50v2/conv4_block3_2_bn/beta:0: (256,)\n",
      "resnet50v2/conv4_block3_2_bn/gamma:0: (256,)\n",
      "resnet50v2/conv4_block3_2_bn/moving_mean:0: (256,)\n",
      "resnet50v2/conv4_block3_2_bn/moving_variance:0: (256,)\n",
      "resnet50v2/conv4_block3_2_conv/kernel:0: (3, 3, 256, 256)\n",
      "resnet50v2/conv4_block3_3_conv/bias:0: (1024,)\n",
      "resnet50v2/conv4_block3_3_conv/kernel:0: (1, 1, 256, 1024)\n",
      "resnet50v2/conv4_block3_preact_bn/beta:0: (1024,)\n",
      "resnet50v2/conv4_block3_preact_bn/gamma:0: (1024,)\n",
      "resnet50v2/conv4_block3_preact_bn/moving_mean:0: (1024,)\n",
      "resnet50v2/conv4_block3_preact_bn/moving_variance:0: (1024,)\n",
      "resnet50v2/conv4_block4_1_bn/beta:0: (256,)\n",
      "resnet50v2/conv4_block4_1_bn/gamma:0: (256,)\n",
      "resnet50v2/conv4_block4_1_bn/moving_mean:0: (256,)\n",
      "resnet50v2/conv4_block4_1_bn/moving_variance:0: (256,)\n",
      "resnet50v2/conv4_block4_1_conv/kernel:0: (1, 1, 1024, 256)\n",
      "resnet50v2/conv4_block4_2_bn/beta:0: (256,)\n",
      "resnet50v2/conv4_block4_2_bn/gamma:0: (256,)\n",
      "resnet50v2/conv4_block4_2_bn/moving_mean:0: (256,)\n",
      "resnet50v2/conv4_block4_2_bn/moving_variance:0: (256,)\n",
      "resnet50v2/conv4_block4_2_conv/kernel:0: (3, 3, 256, 256)\n",
      "resnet50v2/conv4_block4_3_conv/bias:0: (1024,)\n",
      "resnet50v2/conv4_block4_3_conv/kernel:0: (1, 1, 256, 1024)\n",
      "resnet50v2/conv4_block4_preact_bn/beta:0: (1024,)\n",
      "resnet50v2/conv4_block4_preact_bn/gamma:0: (1024,)\n",
      "resnet50v2/conv4_block4_preact_bn/moving_mean:0: (1024,)\n",
      "resnet50v2/conv4_block4_preact_bn/moving_variance:0: (1024,)\n",
      "resnet50v2/conv4_block5_1_bn/beta:0: (256,)\n",
      "resnet50v2/conv4_block5_1_bn/gamma:0: (256,)\n",
      "resnet50v2/conv4_block5_1_bn/moving_mean:0: (256,)\n",
      "resnet50v2/conv4_block5_1_bn/moving_variance:0: (256,)\n",
      "resnet50v2/conv4_block5_1_conv/kernel:0: (1, 1, 1024, 256)\n",
      "resnet50v2/conv4_block5_2_bn/beta:0: (256,)\n",
      "resnet50v2/conv4_block5_2_bn/gamma:0: (256,)\n",
      "resnet50v2/conv4_block5_2_bn/moving_mean:0: (256,)\n",
      "resnet50v2/conv4_block5_2_bn/moving_variance:0: (256,)\n",
      "resnet50v2/conv4_block5_2_conv/kernel:0: (3, 3, 256, 256)\n",
      "resnet50v2/conv4_block5_3_conv/bias:0: (1024,)\n",
      "resnet50v2/conv4_block5_3_conv/kernel:0: (1, 1, 256, 1024)\n",
      "resnet50v2/conv4_block5_preact_bn/beta:0: (1024,)\n",
      "resnet50v2/conv4_block5_preact_bn/gamma:0: (1024,)\n",
      "resnet50v2/conv4_block5_preact_bn/moving_mean:0: (1024,)\n",
      "resnet50v2/conv4_block5_preact_bn/moving_variance:0: (1024,)\n",
      "resnet50v2/conv4_block6_1_bn/beta:0: (256,)\n",
      "resnet50v2/conv4_block6_1_bn/gamma:0: (256,)\n",
      "resnet50v2/conv4_block6_1_bn/moving_mean:0: (256,)\n",
      "resnet50v2/conv4_block6_1_bn/moving_variance:0: (256,)\n",
      "resnet50v2/conv4_block6_1_conv/kernel:0: (1, 1, 1024, 256)\n",
      "resnet50v2/conv4_block6_2_bn/beta:0: (256,)\n",
      "resnet50v2/conv4_block6_2_bn/gamma:0: (256,)\n",
      "resnet50v2/conv4_block6_2_bn/moving_mean:0: (256,)\n",
      "resnet50v2/conv4_block6_2_bn/moving_variance:0: (256,)\n",
      "resnet50v2/conv4_block6_2_conv/kernel:0: (3, 3, 256, 256)\n",
      "resnet50v2/conv4_block6_3_conv/bias:0: (1024,)\n",
      "resnet50v2/conv4_block6_3_conv/kernel:0: (1, 1, 256, 1024)\n",
      "resnet50v2/conv4_block6_preact_bn/beta:0: (1024,)\n",
      "resnet50v2/conv4_block6_preact_bn/gamma:0: (1024,)\n",
      "resnet50v2/conv4_block6_preact_bn/moving_mean:0: (1024,)\n",
      "resnet50v2/conv4_block6_preact_bn/moving_variance:0: (1024,)\n",
      "resnet50v2/conv5_block1_0_conv/bias:0: (2048,)\n",
      "resnet50v2/conv5_block1_0_conv/kernel:0: (1, 1, 1024, 2048)\n",
      "resnet50v2/conv5_block1_1_bn/beta:0: (512,)\n",
      "resnet50v2/conv5_block1_1_bn/gamma:0: (512,)\n",
      "resnet50v2/conv5_block1_1_bn/moving_mean:0: (512,)\n",
      "resnet50v2/conv5_block1_1_bn/moving_variance:0: (512,)\n",
      "resnet50v2/conv5_block1_1_conv/kernel:0: (1, 1, 1024, 512)\n",
      "resnet50v2/conv5_block1_2_bn/beta:0: (512,)\n",
      "resnet50v2/conv5_block1_2_bn/gamma:0: (512,)\n",
      "resnet50v2/conv5_block1_2_bn/moving_mean:0: (512,)\n",
      "resnet50v2/conv5_block1_2_bn/moving_variance:0: (512,)\n",
      "resnet50v2/conv5_block1_2_conv/kernel:0: (3, 3, 512, 512)\n",
      "resnet50v2/conv5_block1_3_conv/bias:0: (2048,)\n",
      "resnet50v2/conv5_block1_3_conv/kernel:0: (1, 1, 512, 2048)\n",
      "resnet50v2/conv5_block1_preact_bn/beta:0: (1024,)\n",
      "resnet50v2/conv5_block1_preact_bn/gamma:0: (1024,)\n",
      "resnet50v2/conv5_block1_preact_bn/moving_mean:0: (1024,)\n",
      "resnet50v2/conv5_block1_preact_bn/moving_variance:0: (1024,)\n",
      "resnet50v2/conv5_block2_1_bn/beta:0: (512,)\n",
      "resnet50v2/conv5_block2_1_bn/gamma:0: (512,)\n",
      "resnet50v2/conv5_block2_1_bn/moving_mean:0: (512,)\n",
      "resnet50v2/conv5_block2_1_bn/moving_variance:0: (512,)\n",
      "resnet50v2/conv5_block2_1_conv/kernel:0: (1, 1, 2048, 512)\n",
      "resnet50v2/conv5_block2_2_bn/beta:0: (512,)\n",
      "resnet50v2/conv5_block2_2_bn/gamma:0: (512,)\n",
      "resnet50v2/conv5_block2_2_bn/moving_mean:0: (512,)\n",
      "resnet50v2/conv5_block2_2_bn/moving_variance:0: (512,)\n",
      "resnet50v2/conv5_block2_2_conv/kernel:0: (3, 3, 512, 512)\n",
      "resnet50v2/conv5_block2_3_conv/bias:0: (2048,)\n",
      "resnet50v2/conv5_block2_3_conv/kernel:0: (1, 1, 512, 2048)\n",
      "resnet50v2/conv5_block2_preact_bn/beta:0: (2048,)\n",
      "resnet50v2/conv5_block2_preact_bn/gamma:0: (2048,)\n",
      "resnet50v2/conv5_block2_preact_bn/moving_mean:0: (2048,)\n",
      "resnet50v2/conv5_block2_preact_bn/moving_variance:0: (2048,)\n",
      "resnet50v2/conv5_block3_1_bn/beta:0: (512,)\n",
      "resnet50v2/conv5_block3_1_bn/gamma:0: (512,)\n",
      "resnet50v2/conv5_block3_1_bn/moving_mean:0: (512,)\n",
      "resnet50v2/conv5_block3_1_bn/moving_variance:0: (512,)\n",
      "resnet50v2/conv5_block3_1_conv/kernel:0: (1, 1, 2048, 512)\n",
      "resnet50v2/conv5_block3_2_bn/beta:0: (512,)\n",
      "resnet50v2/conv5_block3_2_bn/gamma:0: (512,)\n",
      "resnet50v2/conv5_block3_2_bn/moving_mean:0: (512,)\n",
      "resnet50v2/conv5_block3_2_bn/moving_variance:0: (512,)\n",
      "resnet50v2/conv5_block3_2_conv/kernel:0: (3, 3, 512, 512)\n",
      "resnet50v2/conv5_block3_3_conv/bias:0: (2048,)\n",
      "resnet50v2/conv5_block3_3_conv/kernel:0: (1, 1, 512, 2048)\n",
      "resnet50v2/conv5_block3_preact_bn/beta:0: (2048,)\n",
      "resnet50v2/conv5_block3_preact_bn/gamma:0: (2048,)\n",
      "resnet50v2/conv5_block3_preact_bn/moving_mean:0: (2048,)\n",
      "resnet50v2/conv5_block3_preact_bn/moving_variance:0: (2048,)\n",
      "resnet50v2/post_bn/beta:0: (2048,)\n",
      "resnet50v2/post_bn/gamma:0: (2048,)\n",
      "resnet50v2/post_bn/moving_mean:0: (2048,)\n",
      "resnet50v2/post_bn/moving_variance:0: (2048,)\n"
     ]
    }
   ],
   "source": [
    "# Load the weights file to inspect its structure\n",
    "import h5py\n",
    "\n",
    "with h5py.File('checkpoints/model_checkpoint.h5', 'r') as f:\n",
    "    # Print the keys to see the layer names and shapes\n",
    "    def print_structure(name, obj):\n",
    "        if isinstance(obj, h5py.Dataset):\n",
    "            print(f\"{name}: {obj.shape}\")\n",
    "    \n",
    "    print(\"Weight file structure:\")\n",
    "    f.visititems(print_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading weights for layer: batch_normalization\n",
      "Loading batch_normalization/batch_normalization/gamma:0\n",
      "Weight shape in file: (2048,)\n",
      "Layer weight shape: (2048,)\n",
      "Loading batch_normalization/batch_normalization/beta:0\n",
      "Weight shape in file: (2048,)\n",
      "Layer weight shape: (2048,)\n",
      "Loading batch_normalization/batch_normalization/moving_mean:0\n",
      "Weight shape in file: (2048,)\n",
      "Layer weight shape: (2048,)\n",
      "Loading batch_normalization/batch_normalization/moving_variance:0\n",
      "Weight shape in file: (2048,)\n",
      "Layer weight shape: (2048,)\n",
      "\n",
      "Loading weights for layer: dense_4\n",
      "Loading dense_4/dense_4/kernel:0\n",
      "Weight shape in file: (2048, 512)\n",
      "Layer weight shape: (2048, 512)\n",
      "Loading dense_4/dense_4/bias:0\n",
      "Weight shape in file: (512,)\n",
      "Layer weight shape: (512,)\n",
      "\n",
      "Loading weights for layer: dense_5\n",
      "Loading dense_5/dense_5/kernel:0\n",
      "Weight shape in file: (512, 256)\n",
      "Layer weight shape: (512, 256)\n",
      "Loading dense_5/dense_5/bias:0\n",
      "Weight shape in file: (256,)\n",
      "Layer weight shape: (256,)\n",
      "\n",
      "Loading weights for layer: dense_6\n",
      "Loading dense_6/dense_6/kernel:0\n",
      "Weight shape in file: (256, 10)\n",
      "Layer weight shape: (256, 10)\n",
      "Loading dense_6/dense_6/bias:0\n",
      "Weight shape in file: (10,)\n",
      "Layer weight shape: (10,)\n",
      "1/1 [==============================] - 0s 425ms/step\n",
      "\n",
      "Results for classification_3.png:\n",
      "Butterfly: 100.00%\n",
      "Spider: 0.00%\n",
      "Dog: 0.00%\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "\n",
      "Results for classification_4.png:\n",
      "Goat: 99.72%\n",
      "Cow: 0.28%\n",
      "Cat: 0.00%\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "\n",
      "Results for classification_5.png:\n",
      "Squirrel: 100.00%\n",
      "Dog: 0.00%\n",
      "Cat: 0.00%\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "\n",
      "Results for classification_6.png:\n",
      "Cow: 51.01%\n",
      "Horse: 48.99%\n",
      "Goat: 0.01%\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "\n",
      "Results for classification_7.png:\n",
      "Dog: 100.00%\n",
      "Cat: 0.00%\n",
      "Goat: 0.00%\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "\n",
      "Results for classification_8.png:\n",
      "Chicken: 98.18%\n",
      "Cat: 1.82%\n",
      "Horse: 0.00%\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "\n",
      "Results for classification_9.png:\n",
      "Dog: 100.00%\n",
      "Goat: 0.00%\n",
      "Cow: 0.00%\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "\n",
      "Results for classification_10.png:\n",
      "Horse: 100.00%\n",
      "Dog: 0.00%\n",
      "Cow: 0.00%\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "\n",
      "Results for classification_11.png:\n",
      "Horse: 100.00%\n",
      "Cow: 0.00%\n",
      "Dog: 0.00%\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "\n",
      "Results for classification_12.png:\n",
      "Butterfly: 100.00%\n",
      "Spider: 0.00%\n",
      "Chicken: 0.00%\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "\n",
      "Results for classification_13.png:\n",
      "Horse: 100.00%\n",
      "Cow: 0.00%\n",
      "Elephant: 0.00%\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "\n",
      "Results for classification_14.png:\n",
      "Cow: 100.00%\n",
      "Goat: 0.00%\n",
      "Horse: 0.00%\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "\n",
      "Results for classification_15.png:\n",
      "Goat: 99.67%\n",
      "Cow: 0.24%\n",
      "Horse: 0.07%\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "\n",
      "Results for classification_16.png:\n",
      "Spider: 100.00%\n",
      "Butterfly: 0.00%\n",
      "Cat: 0.00%\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "\n",
      "Results for classification_17.png:\n",
      "Squirrel: 99.15%\n",
      "Elephant: 0.59%\n",
      "Goat: 0.18%\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "\n",
      "Results for classification_18.png:\n",
      "Dog: 100.00%\n",
      "Cat: 0.00%\n",
      "Goat: 0.00%\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "\n",
      "Results for classification_19.png:\n",
      "Squirrel: 99.98%\n",
      "Goat: 0.01%\n",
      "Cat: 0.00%\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "\n",
      "Results for classification_20.png:\n",
      "Dog: 67.84%\n",
      "Cow: 14.93%\n",
      "Goat: 10.34%\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "\n",
      "Results for classification_21.png:\n",
      "Spider: 100.00%\n",
      "Butterfly: 0.00%\n",
      "Dog: 0.00%\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "\n",
      "Results for classification_22.png:\n",
      "Goat: 99.98%\n",
      "Cow: 0.02%\n",
      "Horse: 0.00%\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "\n",
      "Results for classification_23.png:\n",
      "Spider: 100.00%\n",
      "Butterfly: 0.00%\n",
      "Squirrel: 0.00%\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "\n",
      "Results for classification_24.png:\n",
      "Chicken: 99.67%\n",
      "Cat: 0.33%\n",
      "Goat: 0.00%\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "\n",
      "Results for classification_25.png:\n",
      "Cat: 88.85%\n",
      "Chicken: 11.14%\n",
      "Dog: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os\n",
    "import random\n",
    "\n",
    "# First recreate the model architecture\n",
    "base_model = applications.ResNet50V2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create the model with exact layer names\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(name='global_average_pooling2d'),\n",
    "    layers.BatchNormalization(name='batch_normalization'),\n",
    "    layers.Dense(512, activation='relu', name='dense_4'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu', name='dense_5'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax', name='dense_6')\n",
    "])\n",
    "\n",
    "# Build the model with a sample input\n",
    "dummy_input = tf.random.normal((1, 224, 224, 3))\n",
    "_ = model(dummy_input)\n",
    "\n",
    "# Load weights layer by layer\n",
    "with h5py.File('checkpoints/model_checkpoint.h5', 'r') as f:\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.Model):  # Skip the base model since it uses pretrained weights\n",
    "            continue\n",
    "        if hasattr(layer, 'weights') and len(layer.weights) > 0:\n",
    "            print(f\"\\nLoading weights for layer: {layer.name}\")\n",
    "            for weight in layer.weights:\n",
    "                weight_name = weight.name.replace(layer.name + '/', '')\n",
    "                weight_path = f\"{layer.name}/{layer.name}/{weight_name}\"\n",
    "                if weight_path in f:\n",
    "                    print(f\"Loading {weight_path}\")\n",
    "                    weight_value = f[weight_path][:]\n",
    "                    print(f\"Weight shape in file: {weight_value.shape}\")\n",
    "                    print(f\"Layer weight shape: {weight.shape}\")\n",
    "                    if weight_value.shape == weight.shape:\n",
    "                        weight.assign(weight_value)\n",
    "                    else:\n",
    "                        print(f\"Shape mismatch for {weight_path}\")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array, img\n",
    "\n",
    "# Modified function to predict and save results\n",
    "def predict_and_save(image_path, class_names, save_path):\n",
    "    img_array, original_img = preprocess_image(image_path)\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = np.max(predictions[0]) * 100\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(original_img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Predicted: {predicted_class}\\nConfidence: {confidence:.2f}%')\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    \n",
    "    # Print predictions\n",
    "    top_3_idx = np.argsort(predictions[0])[-3:][::-1]\n",
    "    print(f\"\\nResults for {os.path.basename(save_path)}:\")\n",
    "    for idx in top_3_idx:\n",
    "        print(f\"{class_names[idx]}: {predictions[0][idx]*100:.2f}%\")\n",
    "\n",
    "# Define your class names\n",
    "class_names = ['Butterfly', 'Cat', 'Chicken', 'Cow', 'Dog', \n",
    "               'Elephant', 'Horse', 'Spider', 'Goat', 'Squirrel']\n",
    "\n",
    "# Create inference_examples directory if it doesn't exist\n",
    "os.makedirs('inference_examples', exist_ok=True)\n",
    "\n",
    "# Get all test images\n",
    "test_folder = \"dataset/test\"\n",
    "test_images = [f for f in os.listdir(test_folder) if f.endswith('.jpeg')]\n",
    "\n",
    "# Run predictions on 23 random images\n",
    "for i in range(23):\n",
    "    random_image = random.choice(test_images)\n",
    "    test_image_path = os.path.join(test_folder, random_image)\n",
    "    save_path = f'inference_examples/classification_{i+3}.png'  # Start from _3\n",
    "    predict_and_save(test_image_path, class_names, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
