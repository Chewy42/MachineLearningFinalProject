{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at dataset\\raw-img. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_dir = \"dataset\"\n",
    "raw_img_dir = os.path.join(dataset_dir, \"raw-img\")\n",
    "\n",
    "if os.path.exists(raw_img_dir) and len(os.listdir(raw_img_dir)) > 0:\n",
    "    print(f\"Dataset already exists at {raw_img_dir}. Skipping download.\")\n",
    "else:\n",
    "    print(\"Dataset not found. Attempting to download...\")\n",
    "    try:\n",
    "        import kagglehub\n",
    "        dataset_path = kagglehub.dataset_download(\"alessiocorrado99/animals10\", path=dataset_dir)\n",
    "        print(f\"Dataset downloaded to: {dataset_path}\")\n",
    "    except ImportError:\n",
    "        print(\"kagglehub not found. Please install it using 'pip install kagglehub'\")\n",
    "        print(\"Attempting manual download...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading dataset: {e}\")\n",
    "        print(f\"Please ensure kagglehub is properly configured and the dataset exists.\")\n",
    "        print(f\"You can also manually download the dataset from Kaggle to {dataset_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for class_name in os.listdir(f\"{dataset_dir}/raw-img\"):\n",
    "    for filename in os.listdir(f\"{dataset_dir}/raw-img/{class_name}\"):\n",
    "        data.append({\"filename\": f\"{dataset_dir}/raw-img/{class_name}/{filename}\", \"class\": class_name})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(f\"{dataset_dir}/_annotations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split and reorganized into train, test, and valid directories.\n"
     ]
    }
   ],
   "source": [
    "# Read the annotations file\n",
    "df = pd.read_csv(f\"{dataset_dir}/_annotations.csv\")\n",
    "\n",
    "# Create train, test, valid directories\n",
    "for split in ['train', 'test', 'valid']:\n",
    "    os.makedirs(os.path.join(dataset_dir, split), exist_ok=True)\n",
    "\n",
    "# Split the data\n",
    "train_df, test_valid_df = train_test_split(df, test_size=0.3, stratify=df['class'], random_state=42)\n",
    "valid_df, test_df = train_test_split(test_valid_df, test_size=0.5, stratify=test_valid_df['class'], random_state=42)\n",
    "\n",
    "# Function to copy files and create new annotations\n",
    "def process_split(split_df, split_name):\n",
    "    new_annotations = []\n",
    "    for _, row in split_df.iterrows():\n",
    "        src = row['filename']\n",
    "        dst = os.path.join(dataset_dir, split_name, os.path.basename(src))\n",
    "        shutil.copy(src, dst)\n",
    "        new_annotations.append({'filename': os.path.basename(src), 'class': row['class']})\n",
    "    \n",
    "    new_df = pd.DataFrame(new_annotations)\n",
    "    new_df.to_csv(os.path.join(dataset_dir, f'{split_name}_annotations.csv'), index=False)\n",
    "\n",
    "# Process each split\n",
    "process_split(train_df, 'train')\n",
    "process_split(valid_df, 'valid')\n",
    "process_split(test_df, 'test')\n",
    "\n",
    "print(\"Data split and reorganized into train, test, and valid directories.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18325 validated image filenames belonging to 10 classes.\n",
      "Found 3927 validated image filenames belonging to 10 classes.\n",
      "Found 18325 images belonging to 10 classes in the training set.\n",
      "Found 3927 images belonging to 10 classes in the validation set.\n"
     ]
    }
   ],
   "source": [
    "# Set up paths\n",
    "dataset_dir = \"dataset\"\n",
    "raw_img_dir = os.path.join(dataset_dir, \"raw-img\")\n",
    "annotations_file = os.path.join(dataset_dir, \"_annotations.csv\")\n",
    "\n",
    "# Create annotations file if it doesn't exist\n",
    "if not os.path.exists(annotations_file):\n",
    "    data = []\n",
    "    for class_name in os.listdir(raw_img_dir):\n",
    "        class_dir = os.path.join(raw_img_dir, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            data.append({\"filename\": os.path.join(class_dir, filename), \"class\": class_name})\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(annotations_file, index=False)\n",
    "\n",
    "# Read the annotations file\n",
    "df = pd.read_csv(annotations_file)\n",
    "\n",
    "# Create train, test, valid directories\n",
    "for split in ['train', 'test', 'valid']:\n",
    "    os.makedirs(os.path.join(dataset_dir, split), exist_ok=True)\n",
    "\n",
    "# Split the data\n",
    "train_df, test_valid_df = train_test_split(df, test_size=0.3, stratify=df['class'], random_state=42)\n",
    "valid_df, test_df = train_test_split(test_valid_df, test_size=0.5, stratify=test_valid_df['class'], random_state=42)\n",
    "\n",
    "# Function to create new annotations\n",
    "def create_split_annotations(split_df, split_name):\n",
    "    split_dir = os.path.join(dataset_dir, split_name)\n",
    "    split_df['filename'] = split_df['filename'].apply(lambda x: os.path.join(split_dir, os.path.basename(x)))\n",
    "    split_df.to_csv(os.path.join(dataset_dir, f'{split_name}_annotations.csv'), index=False)\n",
    "\n",
    "# Create split annotations\n",
    "create_split_annotations(train_df, 'train')\n",
    "create_split_annotations(valid_df, 'valid')\n",
    "create_split_annotations(test_df, 'test')\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Set up data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Load and preprocess the data\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=pd.read_csv(os.path.join(dataset_dir, 'train_annotations.csv')),\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=pd.read_csv(os.path.join(dataset_dir, 'valid_annotations.csv')),\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "print(f\"Found {len(train_generator.filenames)} images belonging to {len(train_generator.class_indices)} classes in the training set.\")\n",
    "print(f\"Found {len(validation_generator.filenames)} images belonging to {len(validation_generator.class_indices)} classes in the validation set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94668760/94668760 [==============================] - 6s 0us/step\n",
      "Phase 1: Training top layers...\n",
      "Epoch 1/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.9326 - accuracy: 0.7121\n",
      "Epoch 1: val_accuracy improved from -inf to 0.91547, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 336s 1s/step - loss: 0.9326 - accuracy: 0.7121 - val_loss: 0.2960 - val_accuracy: 0.9155 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.4437 - accuracy: 0.8653\n",
      "Epoch 2: val_accuracy improved from 0.91547 to 0.92572, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 297s 1s/step - loss: 0.4437 - accuracy: 0.8653 - val_loss: 0.2472 - val_accuracy: 0.9257 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.3781 - accuracy: 0.8842\n",
      "Epoch 3: val_accuracy did not improve from 0.92572\n",
      "286/286 [==============================] - 297s 1s/step - loss: 0.3781 - accuracy: 0.8842 - val_loss: 0.2316 - val_accuracy: 0.9249 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.3381 - accuracy: 0.8964\n",
      "Epoch 4: val_accuracy improved from 0.92572 to 0.92802, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 301s 1s/step - loss: 0.3381 - accuracy: 0.8964 - val_loss: 0.2366 - val_accuracy: 0.9280 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.3022 - accuracy: 0.9046\n",
      "Epoch 5: val_accuracy improved from 0.92802 to 0.93519, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 302s 1s/step - loss: 0.3022 - accuracy: 0.9046 - val_loss: 0.2151 - val_accuracy: 0.9352 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2829 - accuracy: 0.9096\n",
      "Epoch 6: val_accuracy improved from 0.93519 to 0.93648, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 290s 1s/step - loss: 0.2829 - accuracy: 0.9096 - val_loss: 0.2091 - val_accuracy: 0.9365 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.9147\n",
      "Epoch 7: val_accuracy did not improve from 0.93648\n",
      "286/286 [==============================] - 294s 1s/step - loss: 0.2763 - accuracy: 0.9147 - val_loss: 0.2126 - val_accuracy: 0.9360 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2581 - accuracy: 0.9174\n",
      "Epoch 8: val_accuracy did not improve from 0.93648\n",
      "286/286 [==============================] - 296s 1s/step - loss: 0.2581 - accuracy: 0.9174 - val_loss: 0.2092 - val_accuracy: 0.9344 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2457 - accuracy: 0.9230\n",
      "Epoch 9: val_accuracy improved from 0.93648 to 0.94083, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 296s 1s/step - loss: 0.2457 - accuracy: 0.9230 - val_loss: 0.2013 - val_accuracy: 0.9408 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2356 - accuracy: 0.9254\n",
      "Epoch 10: val_accuracy improved from 0.94083 to 0.94185, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 295s 1s/step - loss: 0.2356 - accuracy: 0.9254 - val_loss: 0.2118 - val_accuracy: 0.9419 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.9279\n",
      "Epoch 11: val_accuracy improved from 0.94185 to 0.94493, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 299s 1s/step - loss: 0.2295 - accuracy: 0.9279 - val_loss: 0.1886 - val_accuracy: 0.9449 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2266 - accuracy: 0.9289\n",
      "Epoch 12: val_accuracy improved from 0.94493 to 0.94621, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 302s 1s/step - loss: 0.2266 - accuracy: 0.9289 - val_loss: 0.1854 - val_accuracy: 0.9462 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2211 - accuracy: 0.9289\n",
      "Epoch 13: val_accuracy did not improve from 0.94621\n",
      "286/286 [==============================] - 291s 1s/step - loss: 0.2211 - accuracy: 0.9289 - val_loss: 0.1963 - val_accuracy: 0.9447 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2160 - accuracy: 0.9321\n",
      "Epoch 14: val_accuracy did not improve from 0.94621\n",
      "286/286 [==============================] - 293s 1s/step - loss: 0.2160 - accuracy: 0.9321 - val_loss: 0.2002 - val_accuracy: 0.9413 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2098 - accuracy: 0.9340\n",
      "Epoch 15: val_accuracy did not improve from 0.94621\n",
      "286/286 [==============================] - 291s 1s/step - loss: 0.2098 - accuracy: 0.9340 - val_loss: 0.1986 - val_accuracy: 0.9408 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2055 - accuracy: 0.9360\n",
      "Epoch 16: val_accuracy did not improve from 0.94621\n",
      "286/286 [==============================] - 293s 1s/step - loss: 0.2055 - accuracy: 0.9360 - val_loss: 0.1825 - val_accuracy: 0.9462 - lr: 2.0000e-05\n",
      "Epoch 17/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.9369\n",
      "Epoch 17: val_accuracy did not improve from 0.94621\n",
      "286/286 [==============================] - 295s 1s/step - loss: 0.1990 - accuracy: 0.9369 - val_loss: 0.1906 - val_accuracy: 0.9452 - lr: 2.0000e-05\n",
      "Epoch 18/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1950 - accuracy: 0.9371\n",
      "Epoch 18: val_accuracy improved from 0.94621 to 0.94672, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 296s 1s/step - loss: 0.1950 - accuracy: 0.9371 - val_loss: 0.1918 - val_accuracy: 0.9467 - lr: 2.0000e-05\n",
      "Epoch 19/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1945 - accuracy: 0.9379\n",
      "Epoch 19: val_accuracy did not improve from 0.94672\n",
      "286/286 [==============================] - 296s 1s/step - loss: 0.1945 - accuracy: 0.9379 - val_loss: 0.1916 - val_accuracy: 0.9424 - lr: 2.0000e-05\n",
      "Epoch 20/20\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 0.9405\n",
      "Epoch 20: val_accuracy did not improve from 0.94672\n",
      "286/286 [==============================] - 295s 1s/step - loss: 0.1875 - accuracy: 0.9405 - val_loss: 0.2028 - val_accuracy: 0.9390 - lr: 4.0000e-06\n",
      "\n",
      "Phase 2: Fine-tuning ResNet layers...\n",
      "Epoch 1/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2598 - accuracy: 0.9156\n",
      "Epoch 1: val_accuracy did not improve from 0.94672\n",
      "286/286 [==============================] - 449s 2s/step - loss: 0.2598 - accuracy: 0.9156 - val_loss: 0.2056 - val_accuracy: 0.9337 - lr: 1.0000e-05\n",
      "Epoch 2/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.2084 - accuracy: 0.9335\n",
      "Epoch 2: val_accuracy did not improve from 0.94672\n",
      "286/286 [==============================] - 452s 2s/step - loss: 0.2084 - accuracy: 0.9335 - val_loss: 0.2082 - val_accuracy: 0.9413 - lr: 1.0000e-05\n",
      "Epoch 3/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 0.9408\n",
      "Epoch 3: val_accuracy did not improve from 0.94672\n",
      "286/286 [==============================] - 455s 2s/step - loss: 0.1875 - accuracy: 0.9408 - val_loss: 0.1957 - val_accuracy: 0.9465 - lr: 1.0000e-05\n",
      "Epoch 4/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1826 - accuracy: 0.9426\n",
      "Epoch 4: val_accuracy did not improve from 0.94672\n",
      "286/286 [==============================] - 455s 2s/step - loss: 0.1826 - accuracy: 0.9426 - val_loss: 0.1884 - val_accuracy: 0.9467 - lr: 1.0000e-05\n",
      "Epoch 5/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.9480\n",
      "Epoch 5: val_accuracy did not improve from 0.94672\n",
      "286/286 [==============================] - 446s 2s/step - loss: 0.1656 - accuracy: 0.9480 - val_loss: 0.1919 - val_accuracy: 0.9465 - lr: 1.0000e-05\n",
      "Epoch 6/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1512 - accuracy: 0.9524\n",
      "Epoch 6: val_accuracy improved from 0.94672 to 0.94903, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 445s 2s/step - loss: 0.1512 - accuracy: 0.9524 - val_loss: 0.1769 - val_accuracy: 0.9490 - lr: 1.0000e-05\n",
      "Epoch 7/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1513 - accuracy: 0.9504\n",
      "Epoch 7: val_accuracy improved from 0.94903 to 0.95338, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 442s 2s/step - loss: 0.1513 - accuracy: 0.9504 - val_loss: 0.1785 - val_accuracy: 0.9534 - lr: 1.0000e-05\n",
      "Epoch 8/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1349 - accuracy: 0.9568\n",
      "Epoch 8: val_accuracy did not improve from 0.95338\n",
      "286/286 [==============================] - 441s 2s/step - loss: 0.1349 - accuracy: 0.9568 - val_loss: 0.1899 - val_accuracy: 0.9477 - lr: 1.0000e-05\n",
      "Epoch 9/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1271 - accuracy: 0.9593\n",
      "Epoch 9: val_accuracy did not improve from 0.95338\n",
      "286/286 [==============================] - 447s 2s/step - loss: 0.1271 - accuracy: 0.9593 - val_loss: 0.1772 - val_accuracy: 0.9531 - lr: 1.0000e-05\n",
      "Epoch 10/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.9604\n",
      "Epoch 10: val_accuracy improved from 0.95338 to 0.95645, saving model to checkpoints\\model_checkpoint.h5\n",
      "286/286 [==============================] - 446s 2s/step - loss: 0.1226 - accuracy: 0.9604 - val_loss: 0.1715 - val_accuracy: 0.9565 - lr: 2.0000e-06\n",
      "Epoch 11/30\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.9619"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_improved_model(input_shape, num_classes):\n",
    "    # Create base model with pre-trained ResNet50V2\n",
    "    base_model = applications.ResNet50V2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    # Freeze the base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Create the model\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# Create and compile the model\n",
    "model = create_improved_model(input_shape, num_classes)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Create callbacks\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Create checkpoint callback\n",
    "checkpoint_dir = 'checkpoints'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'model_checkpoint.h5')\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Function to load the latest checkpoint\n",
    "def load_latest_checkpoint(model, checkpoint_path):\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Loading weights from checkpoint: {checkpoint_path}\")\n",
    "        model.load_weights(checkpoint_path)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Load checkpoint if it exists\n",
    "load_latest_checkpoint(model, checkpoint_path)\n",
    "\n",
    "# Phase 1: Train only the top layers\n",
    "print(\"Phase 1: Training top layers...\")\n",
    "history1 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Phase 2: Fine-tune the last few layers of ResNet\n",
    "print(\"\\nPhase 2: Fine-tuning ResNet layers...\")\n",
    "base_model = model.layers[0]\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-30]:  # Freeze all but the last 30 layers\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with a lower learning rate\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Continue training\n",
    "history2 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=30,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(f'Test accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Save the model\n",
    "model.save('animal_classification_model.tf')\n",
    "print(\"Model saved as animal_classification_model.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('animal_classification_model.tf')\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    # Load and resize image\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    # Convert to array and add batch dimension\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    # Normalize pixel values\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array, img\n",
    "\n",
    "# Function to predict and display results\n",
    "def predict_and_display(image_path):\n",
    "    # Get class names from your training data\n",
    "    class_names = list(train_generator.class_indices.keys())\n",
    "    \n",
    "    # Preprocess the image\n",
    "    img_array, original_img = preprocess_image(image_path)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = np.max(predictions[0]) * 100\n",
    "    \n",
    "    # Display image and results\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(original_img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Predicted: {predicted_class}\\nConfidence: {confidence:.2f}%')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top 3 predictions\n",
    "    top_3_idx = np.argsort(predictions[0])[-3:][::-1]\n",
    "    print(\"\\nTop 3 Predictions:\")\n",
    "    for idx in top_3_idx:\n",
    "        print(f\"{class_names[idx]}: {predictions[0][idx]*100:.2f}%\")\n",
    "\n",
    "# Example usage - replace with path to your test image\n",
    "test_image_path = \"dataset/test/your_test_image.jpg\"  # Replace with actual path\n",
    "predict_and_display(test_image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
